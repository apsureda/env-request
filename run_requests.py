#!/usr/bin/python

"""Generate Terraform configuration files from a set of predefined templates.

Copyright 2018 Alfonso Palacios <alpalacios@google.com>

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
"""

import argparse
import os
from jinja2 import Environment
from jinja2 import FileSystemLoader
import yaml
import sys
import logging
import json

TEMPLATE_FOLDER = '/workspace/env-request/'
TF_OUT_FOLDER = TEMPLATE_FOLDER + 'terraform/'
REQUESTS_FILE = 'requests.yaml'
tf_config = None

def parse_args(argv):
  parser = argparse.ArgumentParser()
  parser.add_argument('--template-dir', default=TEMPLATE_FOLDER,
                      help='location of tf template files')
  parser.add_argument('--tf-out', default=TF_OUT_FOLDER,
                      help='directory where the generated Terraform files should be written')
  parser.add_argument('--requests', default=REQUESTS_FILE,
                      help='yaml file containing the environment creation requests')
  return parser.parse_args(argv)

def get_requests(requests_file):
  # open the requests file, which is in YAML format
  stream = open(requests_file, "r")
  req_stream = yaml.load_all(stream)
  all_requests = {}
  defaults = None
  allowed_first_level = ['config', 'defaults', 'requests']
  mandatory_req_fields = ['name', 'type']
  global tf_config
  # YAML files can have multiple "documents" go through the file and append all the
  # elements in a single map
  for doc in req_stream:
    for k,v in doc.items():
      # first level items must only contained one of the allowed keys
      if k not in allowed_first_level:
        logging.error('invalid key \'%s\' in requests file' % (k))
        sys.exit(1)
      # get the config section, which must appear only once
      if k == 'config':
        if not tf_config:
          tf_config = v
        else:
          logging.error('\'%s\' defined twice in requests file' % (k))
          sys.exit(1)
      # the defaults section must appear only once
      if k == 'defaults':
        if not defaults:
          defaults = v
        else:
          logging.error('\'%s\' defined twice in requests file' % (k))
          sys.exit(1)
      # append all the requests in a single dictionary
      if k == 'requests':
        for req in v:
          # check if we are missing any of the mandatory fields
          for mf in mandatory_req_fields:
            if not mf in req:
              logging.error('mandatory field \'%s\' missing in request %s' % (mf, req))
              sys.exit(1)
          # the value of the 'name' attribute will be the key in our map
          rk = req['name']
          # check that the request name is unique
          if rk in all_requests:
            logging.error('duplicate declaration of requests with name \'%s\'' % (rk))
            sys.exit(1)
          all_requests[rk] = req
  # now that we have all the requests, apply the default values, if not defined at the request level
  for rk,rv in all_requests.items():
    req_defaults = {}
    # apply first the global defaults
    if 'global' in defaults:
      req_defaults = defaults['global']
    # override BU defaults, if any
    if 'dft_bu' in rv and rv['dft_bu'] in defaults:
      bu_defaults = defaults[rv['dft_bu']]
      for dk,dv in bu_defaults.items():
        req_defaults[dk] = dv
    # now apply the defaults to the request, only of not defined at that level
    if len(req_defaults) > 0:
      for dk,dv in req_defaults.items():
        if dk not in all_requests[rk]:
          all_requests[rk][dk] = dv
  # add  autogenerated values to env requests
  for v in all_requests.values():
    prepare_context(v)
  #print json.dumps(all_requests, sort_keys=True, indent=2)
  return all_requests

def prepare_context(context):
  if context['type'] in ['sandbox', 'appengine']:
    context['short_id'] = get_short_id(context)
    context['project_id'] = get_project_id(context)
  if context['type'] == 'sandbox':
    # In sandbox environments, operations, managers and the dandbox user are owners
    permissions = {}
    permissions['owner'] = context['team_ops'] + context['team_mng'] 
    if 'user_email' in context:
      permissions['owner'].extend([context['user_email']])
    # the rest of the dev team has view access to the sandbox project
    permissions['viewer'] = context['team_dev']
    context['permissions'] = permissions
  elif context['type'] == 'appengine':
    permissions = {}
    permissions['dev'] = {}
    permissions['dev']['appengine.deployer'] = context['team_dev'] 
    permissions['dev']['appengine.serviceAdmin'] = context['team_dev'] 
    permissions['dev']['appengine.appAdmin'] = context['team_ops'] + context['team_mng'] 
    permissions['dev']['appengine.appAdmin'].extend(['[CLOUDBUILD_SA]']) 
    permissions['test'] = {}
    permissions['test']['appengine.codeViewer'] = context['team_dev'] + context['team_qa']
    permissions['test']['appengine.serviceAdmin'] = context['team_ops'] 
    permissions['test']['appengine.appViewer'] = context['team_mng'] 
    permissions['test']['appengine.appAdmin'] = ['[CLOUDBUILD_SA]']
    permissions['prod'] = {}
    permissions['prod']['appengine.codeViewer'] = context['team_dev'] + context['team_qa']
    permissions['prod']['appengine.serviceAdmin'] = context['team_ops'] 
    permissions['prod']['appengine.appViewer'] = context['team_mng']
    permissions['prod']['appengine.appAdmin'] = ['[CLOUDBUILD_SA]']
    context['permissions'] = permissions
    
def get_short_id(req_config):
  base_name = ''
  if req_config['type'] == 'appengine':
    base_name = '%s-%s' % (req_config['dft_bu'], req_config['name'])
  elif req_config['type'] == 'sandbox':
    base_name = '%s-sb-%s' % (req_config['dft_bu'], req_config['name'])
  return base_name 

def get_project_id(req_config):
  return 'dft-' + get_short_id(req_config)

def generate_tf_files(template_dir, tf_out, tpl_type, prefix, context, replace):
  # initialize jinja2 environment for tf templates
  env = Environment(loader=FileSystemLoader(template_dir), trim_blocks=True)
  # check for templates with the current template type
  template_list = []
  if os.path.isdir(template_dir + '/' + tpl_type):
    template_list = os.listdir(template_dir + '/' + tpl_type)
  if len(template_list) == 0:
    logging.warn('no templates found for request of type \'%s\'' % (tpl_type))
    return False

  # if replace requested, remove previous files. If not requested but previous files
  # present, return.
  for prev_file in os.listdir(tf_out):
    if prev_file.startswith(prefix + '_'):
      if replace:
        os.remove(tf_out + '/' + prev_file)
        logging.info('removing previous file: \'%s\'' %(prev_file))
      else:
        logging.info('ignoring request \'%s\'. Found previous terraform config files.' % (prefix))
        return False
  # apply the selected templates
  for tplfile in template_list:
    # remove junk files
    if tplfile.startswith('.'):
      continue
    template = env.get_template(tpl_type + '/' + tplfile)
    out_file_name = prefix + '_' + tplfile
    logging.info('generating config file: \'%s\'' % (out_file_name))
    out_file = open(tf_out + '/' + out_file_name, "w")
    out_file.write(template.render(context=context))
    out_file.close()
  return True

def main(template_dir, tf_out, requests_file):
  # load the environment requests from the requests file
  envrequests = get_requests(requests_file)

  # create output directory if it doesn't exist yet
  if not os.path.exists(tf_out):
    os.makedirs(tf_out)

  # regenerate the common files (always refreshed)
  generate_tf_files(template_dir, tf_out, 'common', 'common', tf_config, True)

  # generate the tf files of the requested environments
  for k,v in envrequests.items():
    # ask for file regeneration if indicate din requests file
    regenerate = False
    if 'force_update' in v and v['force_update'] == 'true':
      regenerate = True
    file_type = v['type']
    print json.dumps(v, sort_keys=True, indent=2)
    generate_tf_files(template_dir, tf_out, file_type, v['short_id'], v, regenerate)

if __name__ == '__main__':
  logging.getLogger().setLevel(logging.INFO)
  args = parse_args(sys.argv[1:])
  main(args.template_dir, args.tf_out, args.requests)